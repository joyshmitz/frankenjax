#![forbid(unsafe_code)]

#[cfg(test)]
pub mod proptest_strategies;

use serde::{Deserialize, Serialize};
use smallvec::{SmallVec, smallvec};
use std::collections::BTreeMap;
use std::fmt::Write;

#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum CompatibilityMode {
    Strict,
    Hardened,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum DType {
    F32,
    F64,
    I32,
    I64,
    Bool,
}

#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub struct Shape {
    pub dims: Vec<u32>,
}

impl Shape {
    #[must_use]
    pub fn scalar() -> Self {
        Self { dims: Vec::new() }
    }

    #[must_use]
    pub fn vector(len: u32) -> Self {
        Self { dims: vec![len] }
    }

    #[must_use]
    pub fn rank(&self) -> usize {
        self.dims.len()
    }

    #[must_use]
    pub fn element_count(&self) -> Option<u64> {
        self.dims
            .iter()
            .try_fold(1_u64, |acc, dim| acc.checked_mul(u64::from(*dim)))
    }
}

#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub struct AbstractValue {
    pub dtype: DType,
    pub shape: Shape,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Serialize, Deserialize)]
pub enum Primitive {
    Add,
    Mul,
    Dot,
    Sin,
    Cos,
    ReduceSum,
    Reshape,
    Slice,
    Gather,
    Scatter,
    Transpose,
    BroadcastInDim,
    Concatenate,
}

impl Primitive {
    #[must_use]
    pub fn as_str(self) -> &'static str {
        match self {
            Self::Add => "add",
            Self::Mul => "mul",
            Self::Dot => "dot",
            Self::Sin => "sin",
            Self::Cos => "cos",
            Self::ReduceSum => "reduce_sum",
            Self::Reshape => "reshape",
            Self::Slice => "slice",
            Self::Gather => "gather",
            Self::Scatter => "scatter",
            Self::Transpose => "transpose",
            Self::BroadcastInDim => "broadcast_in_dim",
            Self::Concatenate => "concatenate",
        }
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Serialize, Deserialize)]
pub enum Transform {
    Jit,
    Grad,
    Vmap,
}

impl Transform {
    #[must_use]
    pub fn as_str(self) -> &'static str {
        match self {
            Self::Jit => "jit",
            Self::Grad => "grad",
            Self::Vmap => "vmap",
        }
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Hash, Serialize, Deserialize)]
pub struct VarId(pub u32);

#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum Literal {
    I64(i64),
    Bool(bool),
    F64Bits(u64),
}

impl Literal {
    #[must_use]
    pub fn from_f64(value: f64) -> Self {
        Self::F64Bits(value.to_bits())
    }

    #[must_use]
    pub fn as_f64(self) -> Option<f64> {
        match self {
            Self::F64Bits(bits) => Some(f64::from_bits(bits)),
            Self::I64(value) => Some(value as f64),
            Self::Bool(_) => None,
        }
    }

    #[must_use]
    pub fn as_i64(self) -> Option<i64> {
        match self {
            Self::I64(value) => Some(value),
            Self::Bool(_) | Self::F64Bits(_) => None,
        }
    }

    #[must_use]
    pub fn is_integral(self) -> bool {
        matches!(self, Self::I64(_))
    }
}

#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub enum Value {
    Scalar(Literal),
    Tensor(TensorValue),
}

impl Value {
    #[must_use]
    pub fn scalar_i64(value: i64) -> Self {
        Self::Scalar(Literal::I64(value))
    }

    #[must_use]
    pub fn scalar_f64(value: f64) -> Self {
        Self::Scalar(Literal::from_f64(value))
    }

    #[must_use]
    pub fn scalar_bool(value: bool) -> Self {
        Self::Scalar(Literal::Bool(value))
    }

    pub fn vector_i64(values: &[i64]) -> Result<Self, ValueError> {
        let elements = values.iter().copied().map(Literal::I64).collect::<Vec<_>>();
        Ok(Self::Tensor(TensorValue::new(
            DType::I64,
            Shape::vector(values.len() as u32),
            elements,
        )?))
    }

    pub fn vector_f64(values: &[f64]) -> Result<Self, ValueError> {
        let elements = values
            .iter()
            .copied()
            .map(Literal::from_f64)
            .collect::<Vec<_>>();
        Ok(Self::Tensor(TensorValue::new(
            DType::F64,
            Shape::vector(values.len() as u32),
            elements,
        )?))
    }

    #[must_use]
    pub fn as_scalar_literal(&self) -> Option<Literal> {
        match self {
            Self::Scalar(lit) => Some(*lit),
            Self::Tensor(_) => None,
        }
    }

    #[must_use]
    pub fn as_f64_scalar(&self) -> Option<f64> {
        self.as_scalar_literal().and_then(Literal::as_f64)
    }

    #[must_use]
    pub fn as_tensor(&self) -> Option<&TensorValue> {
        match self {
            Self::Scalar(_) => None,
            Self::Tensor(tensor) => Some(tensor),
        }
    }
}

#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub struct TensorValue {
    pub dtype: DType,
    pub shape: Shape,
    pub elements: Vec<Literal>,
}

impl TensorValue {
    pub fn new(dtype: DType, shape: Shape, elements: Vec<Literal>) -> Result<Self, ValueError> {
        let expected_count = shape.element_count().ok_or(ValueError::ShapeOverflow {
            shape: shape.clone(),
        })?;

        if expected_count as usize != elements.len() {
            return Err(ValueError::ElementCountMismatch {
                shape,
                expected_count,
                actual_count: elements.len(),
            });
        }

        Ok(Self {
            dtype,
            shape,
            elements,
        })
    }

    #[must_use]
    pub fn len(&self) -> usize {
        self.elements.len()
    }

    #[must_use]
    pub fn is_empty(&self) -> bool {
        self.elements.is_empty()
    }

    #[must_use]
    pub fn rank(&self) -> usize {
        self.shape.rank()
    }

    #[must_use]
    pub fn leading_dim(&self) -> Option<u32> {
        self.shape.dims.first().copied()
    }

    pub fn slice_axis0(&self, index: usize) -> Result<Value, ValueError> {
        let axis_size = self
            .leading_dim()
            .ok_or(ValueError::RankZeroAxisSliceUnsupported)?;
        if index >= axis_size as usize {
            return Err(ValueError::SliceIndexOutOfBounds {
                index,
                axis_size: axis_size as usize,
            });
        }

        if self.rank() == 1 {
            return Ok(Value::Scalar(self.elements[index]));
        }

        let slice_len = self
            .shape
            .dims
            .iter()
            .skip(1)
            .try_fold(1_usize, |acc, dim| acc.checked_mul(*dim as usize))
            .ok_or(ValueError::ShapeOverflow {
                shape: self.shape.clone(),
            })?;

        let start = index
            .checked_mul(slice_len)
            .ok_or(ValueError::ShapeOverflow {
                shape: self.shape.clone(),
            })?;
        let end = start
            .checked_add(slice_len)
            .ok_or(ValueError::ShapeOverflow {
                shape: self.shape.clone(),
            })?;
        let elements = self.elements[start..end].to_vec();
        let subshape = Shape {
            dims: self.shape.dims[1..].to_vec(),
        };
        Ok(Value::Tensor(TensorValue::new(
            self.dtype, subshape, elements,
        )?))
    }

    pub fn stack_axis0(slices: &[Value]) -> Result<Self, ValueError> {
        if slices.is_empty() {
            return Err(ValueError::EmptyAxisStack);
        }

        match &slices[0] {
            Value::Scalar(first) => {
                let mut elements = Vec::with_capacity(slices.len());
                elements.push(*first);
                for value in &slices[1..] {
                    let Value::Scalar(lit) = value else {
                        return Err(ValueError::MixedAxisStackKinds);
                    };
                    elements.push(*lit);
                }
                let dtype = infer_dtype_from_literals(&elements);
                TensorValue::new(dtype, Shape::vector(slices.len() as u32), elements)
            }
            Value::Tensor(first) => {
                let mut elements = first.elements.clone();
                for value in &slices[1..] {
                    let Value::Tensor(tensor) = value else {
                        return Err(ValueError::MixedAxisStackKinds);
                    };
                    if tensor.dtype != first.dtype {
                        return Err(ValueError::AxisStackDTypeMismatch {
                            expected: first.dtype,
                            actual: tensor.dtype,
                        });
                    }
                    if tensor.shape != first.shape {
                        return Err(ValueError::AxisStackShapeMismatch {
                            expected: first.shape.clone(),
                            actual: tensor.shape.clone(),
                        });
                    }
                    elements.extend_from_slice(&tensor.elements);
                }

                let mut dims = Vec::with_capacity(first.shape.rank() + 1);
                dims.push(slices.len() as u32);
                dims.extend_from_slice(&first.shape.dims);
                TensorValue::new(first.dtype, Shape { dims }, elements)
            }
        }
    }

    pub fn to_f64_vec(&self) -> Option<Vec<f64>> {
        self.elements.iter().copied().map(Literal::as_f64).collect()
    }
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub enum ValueError {
    ShapeOverflow {
        shape: Shape,
    },
    ElementCountMismatch {
        shape: Shape,
        expected_count: u64,
        actual_count: usize,
    },
    RankZeroAxisSliceUnsupported,
    SliceIndexOutOfBounds {
        index: usize,
        axis_size: usize,
    },
    EmptyAxisStack,
    MixedAxisStackKinds,
    AxisStackShapeMismatch {
        expected: Shape,
        actual: Shape,
    },
    AxisStackDTypeMismatch {
        expected: DType,
        actual: DType,
    },
}

impl std::fmt::Display for ValueError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            Self::ShapeOverflow { shape } => {
                write!(f, "shape element count overflowed: {:?}", shape.dims)
            }
            Self::ElementCountMismatch {
                shape,
                expected_count,
                actual_count,
            } => {
                write!(
                    f,
                    "tensor element count mismatch for shape {:?}: expected {}, got {}",
                    shape.dims, expected_count, actual_count
                )
            }
            Self::RankZeroAxisSliceUnsupported => {
                write!(f, "cannot axis-slice rank-0 scalar tensor")
            }
            Self::SliceIndexOutOfBounds { index, axis_size } => {
                write!(
                    f,
                    "axis-slice index {} out of bounds for axis size {}",
                    index, axis_size
                )
            }
            Self::EmptyAxisStack => {
                write!(f, "cannot stack empty slice list")
            }
            Self::MixedAxisStackKinds => {
                write!(f, "cannot stack mixed scalar/tensor slice kinds")
            }
            Self::AxisStackShapeMismatch { expected, actual } => {
                write!(
                    f,
                    "stack shape mismatch: expected {:?}, got {:?}",
                    expected.dims, actual.dims
                )
            }
            Self::AxisStackDTypeMismatch { expected, actual } => {
                write!(
                    f,
                    "stack dtype mismatch: expected {:?}, got {:?}",
                    expected, actual
                )
            }
        }
    }
}

impl std::error::Error for ValueError {}

fn infer_dtype_from_literals(elements: &[Literal]) -> DType {
    if elements
        .iter()
        .all(|literal| matches!(literal, Literal::I64(_)))
    {
        DType::I64
    } else if elements
        .iter()
        .all(|literal| matches!(literal, Literal::Bool(_)))
    {
        DType::Bool
    } else {
        DType::F64
    }
}

#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub enum Atom {
    Var(VarId),
    Lit(Literal),
}

#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub struct Equation {
    pub primitive: Primitive,
    pub inputs: SmallVec<[Atom; 4]>,
    pub outputs: SmallVec<[VarId; 2]>,
    pub params: BTreeMap<String, String>,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct Jaxpr {
    pub invars: Vec<VarId>,
    pub constvars: Vec<VarId>,
    pub outvars: Vec<VarId>,
    pub equations: Vec<Equation>,
    #[serde(skip)]
    fingerprint_cache: std::sync::OnceLock<String>,
}

impl Clone for Jaxpr {
    fn clone(&self) -> Self {
        Self {
            invars: self.invars.clone(),
            constvars: self.constvars.clone(),
            outvars: self.outvars.clone(),
            equations: self.equations.clone(),
            fingerprint_cache: std::sync::OnceLock::new(),
        }
    }
}

impl PartialEq for Jaxpr {
    fn eq(&self, other: &Self) -> bool {
        self.invars == other.invars
            && self.constvars == other.constvars
            && self.outvars == other.outvars
            && self.equations == other.equations
    }
}

impl Eq for Jaxpr {}

impl Jaxpr {
    #[must_use]
    pub fn new(
        invars: Vec<VarId>,
        constvars: Vec<VarId>,
        outvars: Vec<VarId>,
        equations: Vec<Equation>,
    ) -> Self {
        Self {
            invars,
            constvars,
            outvars,
            equations,
            fingerprint_cache: std::sync::OnceLock::new(),
        }
    }

    #[must_use]
    pub fn canonical_fingerprint(&self) -> &str {
        self.fingerprint_cache.get_or_init(|| {
            let mut out = String::new();
            write_var_list(&mut out, "in", &self.invars);
            write_var_list(&mut out, "const", &self.constvars);
            write_var_list(&mut out, "out", &self.outvars);

            for eqn in &self.equations {
                let _ = write!(&mut out, "eqn:{}(", eqn.primitive.as_str());
                for atom in &eqn.inputs {
                    write_atom(&mut out, atom);
                    out.push(',');
                }
                out.push(')');
                out.push_str("->");
                for outvar in &eqn.outputs {
                    let _ = write!(&mut out, "v{},", outvar.0);
                }
                out.push('{');
                for (key, value) in &eqn.params {
                    let _ = write!(&mut out, "{key}={value};");
                }
                out.push('}');
                out.push('|');
            }

            out
        })
    }
}

fn write_var_list(out: &mut String, label: &str, vars: &[VarId]) {
    let _ = write!(out, "{label}=[");
    for var in vars {
        let _ = write!(out, "v{},", var.0);
    }
    out.push(']');
}

fn write_atom(out: &mut String, atom: &Atom) {
    match atom {
        Atom::Var(var) => {
            let _ = write!(out, "v{}", var.0);
        }
        Atom::Lit(lit) => write_literal(out, *lit),
    }
}

fn write_literal(out: &mut String, lit: Literal) {
    match lit {
        Literal::I64(value) => {
            let _ = write!(out, "i64:{value}");
        }
        Literal::Bool(value) => {
            let _ = write!(out, "bool:{value}");
        }
        Literal::F64Bits(value) => {
            let _ = write!(out, "f64bits:{value}");
        }
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum ProgramSpec {
    Add2,
    Square,
    SquarePlusLinear,
    AddOne,
    SinX,
    CosX,
    Dot3,
    ReduceSumVec,
}

#[must_use]
pub fn build_program(spec: ProgramSpec) -> Jaxpr {
    match spec {
        ProgramSpec::Add2 => Jaxpr::new(
            vec![VarId(1), VarId(2)],
            vec![],
            vec![VarId(3)],
            vec![Equation {
                primitive: Primitive::Add,
                inputs: smallvec![Atom::Var(VarId(1)), Atom::Var(VarId(2))],
                outputs: smallvec![VarId(3)],
                params: BTreeMap::new(),
            }],
        ),
        ProgramSpec::Square => Jaxpr::new(
            vec![VarId(1)],
            vec![],
            vec![VarId(2)],
            vec![Equation {
                primitive: Primitive::Mul,
                inputs: smallvec![Atom::Var(VarId(1)), Atom::Var(VarId(1))],
                outputs: smallvec![VarId(2)],
                params: BTreeMap::new(),
            }],
        ),
        ProgramSpec::SquarePlusLinear => Jaxpr::new(
            vec![VarId(1)],
            vec![],
            vec![VarId(4)],
            vec![
                Equation {
                    primitive: Primitive::Mul,
                    inputs: smallvec![Atom::Var(VarId(1)), Atom::Var(VarId(1))],
                    outputs: smallvec![VarId(2)],
                    params: BTreeMap::new(),
                },
                Equation {
                    primitive: Primitive::Mul,
                    inputs: smallvec![Atom::Var(VarId(1)), Atom::Lit(Literal::I64(2))],
                    outputs: smallvec![VarId(3)],
                    params: BTreeMap::new(),
                },
                Equation {
                    primitive: Primitive::Add,
                    inputs: smallvec![Atom::Var(VarId(2)), Atom::Var(VarId(3))],
                    outputs: smallvec![VarId(4)],
                    params: BTreeMap::new(),
                },
            ],
        ),
        ProgramSpec::AddOne => Jaxpr::new(
            vec![VarId(1)],
            vec![],
            vec![VarId(2)],
            vec![Equation {
                primitive: Primitive::Add,
                inputs: smallvec![Atom::Var(VarId(1)), Atom::Lit(Literal::I64(1))],
                outputs: smallvec![VarId(2)],
                params: BTreeMap::new(),
            }],
        ),
        ProgramSpec::SinX => Jaxpr::new(
            vec![VarId(1)],
            vec![],
            vec![VarId(2)],
            vec![Equation {
                primitive: Primitive::Sin,
                inputs: smallvec![Atom::Var(VarId(1))],
                outputs: smallvec![VarId(2)],
                params: BTreeMap::new(),
            }],
        ),
        ProgramSpec::CosX => Jaxpr::new(
            vec![VarId(1)],
            vec![],
            vec![VarId(2)],
            vec![Equation {
                primitive: Primitive::Cos,
                inputs: smallvec![Atom::Var(VarId(1))],
                outputs: smallvec![VarId(2)],
                params: BTreeMap::new(),
            }],
        ),
        ProgramSpec::Dot3 => Jaxpr::new(
            vec![VarId(1), VarId(2)],
            vec![],
            vec![VarId(3)],
            vec![Equation {
                primitive: Primitive::Dot,
                inputs: smallvec![Atom::Var(VarId(1)), Atom::Var(VarId(2))],
                outputs: smallvec![VarId(3)],
                params: BTreeMap::new(),
            }],
        ),
        ProgramSpec::ReduceSumVec => Jaxpr::new(
            vec![VarId(1)],
            vec![],
            vec![VarId(2)],
            vec![Equation {
                primitive: Primitive::ReduceSum,
                inputs: smallvec![Atom::Var(VarId(1))],
                outputs: smallvec![VarId(2)],
                params: BTreeMap::new(),
            }],
        ),
    }
}

#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub struct TraceTransformLedger {
    pub root_jaxpr: Jaxpr,
    pub transform_stack: Vec<Transform>,
    pub transform_evidence: Vec<String>,
}

impl TraceTransformLedger {
    #[must_use]
    pub fn new(root_jaxpr: Jaxpr) -> Self {
        Self {
            root_jaxpr,
            transform_stack: Vec::new(),
            transform_evidence: Vec::new(),
        }
    }

    pub fn push_transform(&mut self, transform: Transform, evidence_id: impl Into<String>) {
        self.transform_stack.push(transform);
        self.transform_evidence.push(evidence_id.into());
    }

    #[must_use]
    pub fn composition_signature(&self) -> String {
        let mut out = String::new();
        out.push_str("stack=");
        for transform in &self.transform_stack {
            let _ = write!(&mut out, "{}>", transform.as_str());
        }
        out.push_str("|jaxpr=");
        out.push_str(self.root_jaxpr.canonical_fingerprint());
        out
    }
}

#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub struct TransformCompositionProof {
    pub stack_signature: String,
    pub stack_hash_hex: String,
    pub transform_count: usize,
    pub evidence_count: usize,
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub enum TransformCompositionError {
    EvidenceCountMismatch {
        transform_count: usize,
        evidence_count: usize,
    },
    EmptyEvidence {
        index: usize,
        transform: Transform,
    },
    UnsupportedSequence {
        detail: String,
    },
}

impl std::fmt::Display for TransformCompositionError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            Self::EvidenceCountMismatch {
                transform_count,
                evidence_count,
            } => {
                write!(
                    f,
                    "transform/evidence cardinality mismatch: transforms={}, evidence={}",
                    transform_count, evidence_count
                )
            }
            Self::EmptyEvidence { index, transform } => {
                write!(
                    f,
                    "transform evidence at index {} for {} is empty",
                    index,
                    transform.as_str()
                )
            }
            Self::UnsupportedSequence { detail } => {
                write!(f, "unsupported transform sequence: {detail}")
            }
        }
    }
}

impl std::error::Error for TransformCompositionError {}

pub fn verify_transform_composition(
    ledger: &TraceTransformLedger,
) -> Result<TransformCompositionProof, TransformCompositionError> {
    if ledger.transform_stack.len() != ledger.transform_evidence.len() {
        return Err(TransformCompositionError::EvidenceCountMismatch {
            transform_count: ledger.transform_stack.len(),
            evidence_count: ledger.transform_evidence.len(),
        });
    }

    for (index, transform) in ledger.transform_stack.iter().enumerate() {
        if ledger.transform_evidence[index].trim().is_empty() {
            return Err(TransformCompositionError::EmptyEvidence {
                index,
                transform: *transform,
            });
        }
    }

    let grad_count = ledger
        .transform_stack
        .iter()
        .filter(|transform| **transform == Transform::Grad)
        .count();
    if grad_count > 1 {
        return Err(TransformCompositionError::UnsupportedSequence {
            detail: "current engine supports at most one grad transform".to_owned(),
        });
    }

    let vmap_count = ledger
        .transform_stack
        .iter()
        .filter(|transform| **transform == Transform::Vmap)
        .count();
    if vmap_count > 1 {
        return Err(TransformCompositionError::UnsupportedSequence {
            detail: "current engine supports at most one vmap transform".to_owned(),
        });
    }

    let stack_signature = ledger.composition_signature();
    let stack_hash_hex = format!("{:016x}", fnv1a_64(stack_signature.as_bytes()));

    Ok(TransformCompositionProof {
        stack_signature,
        stack_hash_hex,
        transform_count: ledger.transform_stack.len(),
        evidence_count: ledger.transform_evidence.len(),
    })
}

fn fnv1a_64(bytes: &[u8]) -> u64 {
    let mut hash = 0xcbf29ce484222325_u64;
    for byte in bytes {
        hash ^= u64::from(*byte);
        hash = hash.wrapping_mul(0x0000_0100_0000_01b3);
    }
    hash
}

#[cfg(test)]
mod tests {
    use super::{
        Literal, ProgramSpec, Shape, TensorValue, TraceTransformLedger, Transform, Value,
        ValueError, build_program, verify_transform_composition,
    };

    #[test]
    fn shape_scalar_rank_is_zero() {
        let scalar = Shape::scalar();
        assert_eq!(scalar.rank(), 0);
        assert_eq!(scalar.element_count(), Some(1));
    }

    #[test]
    fn vector_constructor_builds_tensor_value() {
        let value = Value::vector_i64(&[1, 2, 3]).expect("vector constructor should succeed");
        let tensor = value.as_tensor().expect("expected tensor value");
        assert_eq!(tensor.shape, Shape::vector(3));
        assert_eq!(tensor.len(), 3);
    }

    #[test]
    fn tensor_slice_axis0_on_rank2_returns_rank1_slice() {
        let tensor = TensorValue::new(
            super::DType::I64,
            Shape { dims: vec![2, 3] },
            vec![
                Literal::I64(1),
                Literal::I64(2),
                Literal::I64(3),
                Literal::I64(4),
                Literal::I64(5),
                Literal::I64(6),
            ],
        )
        .expect("rank2 tensor should build");

        let slice = tensor.slice_axis0(1).expect("slice should succeed");
        let Value::Tensor(slice_tensor) = slice else {
            panic!("slice should be tensor");
        };
        assert_eq!(slice_tensor.shape, Shape::vector(3));
        assert_eq!(
            slice_tensor.elements,
            vec![Literal::I64(4), Literal::I64(5), Literal::I64(6)]
        );
    }

    #[test]
    fn stack_axis0_restores_rank2_from_rank1_slices() {
        let row_a = Value::vector_i64(&[1, 2, 3]).expect("vector should build");
        let row_b = Value::vector_i64(&[4, 5, 6]).expect("vector should build");
        let stacked = TensorValue::stack_axis0(&[row_a, row_b]).expect("stack should succeed");
        assert_eq!(stacked.shape, Shape { dims: vec![2, 3] });
        assert_eq!(
            stacked.elements,
            vec![
                Literal::I64(1),
                Literal::I64(2),
                Literal::I64(3),
                Literal::I64(4),
                Literal::I64(5),
                Literal::I64(6)
            ]
        );
    }

    #[test]
    fn tensor_new_rejects_wrong_element_count() {
        let err = TensorValue::new(
            super::DType::I64,
            Shape::vector(4),
            vec![Literal::I64(1), Literal::I64(2)],
        )
        .expect_err("shape mismatch should fail");

        assert!(matches!(err, ValueError::ElementCountMismatch { .. }));
    }

    #[test]
    fn composition_proof_is_deterministic() {
        let mut ttl = TraceTransformLedger::new(build_program(ProgramSpec::Square));
        ttl.push_transform(Transform::Jit, "jit-evidence");
        ttl.push_transform(Transform::Grad, "grad-evidence");

        let proof_a = verify_transform_composition(&ttl).expect("proof should validate");
        let proof_b = verify_transform_composition(&ttl).expect("proof should validate");
        assert_eq!(proof_a.stack_hash_hex, proof_b.stack_hash_hex);
    }

    #[test]
    fn unsupported_sequence_rejected() {
        let mut ttl = TraceTransformLedger::new(build_program(ProgramSpec::Square));
        ttl.push_transform(Transform::Grad, "g1");
        ttl.push_transform(Transform::Grad, "g2");

        let err = verify_transform_composition(&ttl).expect_err("double grad should fail");
        assert!(format!("{err}").contains("at most one grad"));
    }

    #[test]
    fn test_core_test_log_schema_contract() {
        let fixture_id =
            fj_test_utils::fixture_id_from_json(&(1_u32, 2_u32)).expect("fixture digest");
        let log = fj_test_utils::TestLogV1::unit(
            fj_test_utils::test_id(module_path!(), "test_core_test_log_schema_contract"),
            fixture_id,
            fj_test_utils::TestMode::Strict,
            fj_test_utils::TestResult::Pass,
        );
        assert_eq!(log.schema_version, fj_test_utils::TEST_LOG_SCHEMA_VERSION);
    }
}
